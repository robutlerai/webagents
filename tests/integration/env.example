# External Tools Integration Test Configuration

# =================================================================
# OPTION 1: LiteLLM Proxy (Recommended)
# Start LiteLLM proxy server and use it for all LLM calls
# =================================================================

# LiteLLM Proxy URL (if running LiteLLM server)
LITELLM_BASE_URL=http://localhost:2225

# LiteLLM API Key (may be required depending on proxy configuration)
LITELLM_API_KEY=your-litellm-api-key

# =================================================================
# OPTION 2: Direct OpenAI API (Alternative)
# Use OpenAI API directly without LiteLLM proxy
# =================================================================

# OpenAI API Key (for direct API access)
OPENAI_API_KEY=sk-your-openai-api-key-here

# =================================================================
# CONFIGURATION NOTES:
# =================================================================
# 
# 1. If LITELLM_BASE_URL is set, the test will use LiteLLM proxy
# 2. If only OPENAI_API_KEY is set, the test will use direct OpenAI API
# 3. At least one of the above options must be configured
#
# RECOMMENDED SETUP:
# 1. Copy this file: cp env.example .env
# 2. Edit .env with your actual values
# 3. Start LiteLLM server: cd agents && ./start_litellm.sh
# 4. Run integration test: python -m pytest tests/integration/test_external_tools_integration.py -v
#
# =================================================================

# Additional LLM Provider Keys (optional, for LiteLLM proxy)
ANTHROPIC_API_KEY=your-anthropic-api-key
XAI_API_KEY=your-xai-api-key

# Test Configuration
ROBUTLER_LOG_LEVEL=INFO
INTEGRATION_TEST_TIMEOUT=60 